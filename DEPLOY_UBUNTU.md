# Ubuntu æœåŠ¡å™¨éƒ¨ç½²æŒ‡å—

å®Œæ•´çš„UbuntuæœåŠ¡å™¨éƒ¨ç½²æ–¹æ¡ˆï¼ŒåŒ…å«systemdæœåŠ¡è‡ªåŠ¨å¯åŠ¨ã€‚

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Ubuntu 18.04+ / Debian 10+
- **Python**: 3.7+
- **æƒé™**: sudoæƒé™ï¼ˆç”¨äºå®‰è£…ç³»ç»ŸæœåŠ¡ï¼‰
- **ç½‘ç»œ**: å¯è®¿é—®äº’è”ç½‘

## ğŸš€ ä¸€é”®éƒ¨ç½²

### æ–¹æ³•1: è‡ªåŠ¨éƒ¨ç½²è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# 1. ä¸Šä¼ é¡¹ç›®åˆ°æœåŠ¡å™¨
# å¯ä»¥ä½¿ç”¨ scp, rsync, git clone ç­‰æ–¹å¼

# 2. è¿›å…¥é¡¹ç›®ç›®å½•
cd çƒ­ç‚¹çˆ¬å–/

# 3. è¿è¡Œè‡ªåŠ¨éƒ¨ç½²è„šæœ¬
sudo bash deploy.sh
```

éƒ¨ç½²è„šæœ¬ä¼šè‡ªåŠ¨å®Œæˆï¼š
- âœ… æ£€æŸ¥å¹¶å®‰è£…Pythonç¯å¢ƒ
- âœ… å®‰è£…é¡¹ç›®ä¾èµ–
- âœ… åˆ›å»ºæ•°æ®å’Œæ—¥å¿—ç›®å½•
- âœ… æµ‹è¯•è¿è¡Œçˆ¬è™«
- âœ… åˆ›å»ºsystemdæœåŠ¡
- âœ… å¯åŠ¨å¹¶å¯ç”¨æœåŠ¡

### æ–¹æ³•2: æ‰‹åŠ¨éƒ¨ç½²

```bash
# 1. å®‰è£…Pythonå’Œpip
sudo apt update
sudo apt install -y python3 python3-pip

# 2. å®‰è£…é¡¹ç›®ä¾èµ–
pip3 install -r requirements.txt

# 3. æµ‹è¯•è¿è¡Œ
python3 scheduler.py --once

# 4. åˆ›å»ºsystemdæœåŠ¡ï¼ˆè§ä¸‹æ–‡ï¼‰
```

## ğŸ“¦ ä¸Šä¼ é¡¹ç›®åˆ°æœåŠ¡å™¨

### ä½¿ç”¨ SCP

```bash
# ä»æœ¬åœ°ä¸Šä¼ ï¼ˆåœ¨macOSä¸Šæ‰§è¡Œï¼‰
scp -r "/Users/mac/Documents/computerscience/å°å·¥å…·/çƒ­ç‚¹çˆ¬å–" user@your-server:/home/user/
```

### ä½¿ç”¨ rsyncï¼ˆæ¨èï¼‰

```bash
# æ›´é«˜æ•ˆçš„åŒæ­¥æ–¹å¼
rsync -avz --exclude 'data/*' --exclude 'logs/*' \
  "/Users/mac/Documents/computerscience/å°å·¥å…·/çƒ­ç‚¹çˆ¬å–/" \
  user@your-server:/home/user/çƒ­ç‚¹çˆ¬å–/
```

### ä½¿ç”¨ Git

```bash
# å¦‚æœé¡¹ç›®å·²ä¸Šä¼ åˆ°Gitä»“åº“
ssh user@your-server
git clone your-repo-url
cd çƒ­ç‚¹çˆ¬å–
```

## ğŸ”§ systemd æœåŠ¡é…ç½®

### æœåŠ¡æ–‡ä»¶ä½ç½®
`/etc/systemd/system/hotsearch-crawler.service`

### æœåŠ¡é…ç½®å†…å®¹

```ini
[Unit]
Description=07173 Hot Search Crawler
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
User=your-username
WorkingDirectory=/path/to/çƒ­ç‚¹çˆ¬å–
ExecStart=/usr/bin/python3 /path/to/çƒ­ç‚¹çˆ¬å–/scheduler.py
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal

Environment="PYTHONUNBUFFERED=1"

NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

### æ‰‹åŠ¨åˆ›å»ºæœåŠ¡

```bash
# 1. åˆ›å»ºæœåŠ¡æ–‡ä»¶
sudo nano /etc/systemd/system/hotsearch-crawler.service

# 2. ç²˜è´´ä¸Šè¿°é…ç½®å†…å®¹ï¼ˆä¿®æ”¹è·¯å¾„å’Œç”¨æˆ·åï¼‰

# 3. é‡è½½systemd
sudo systemctl daemon-reload

# 4. å¯ç”¨æœåŠ¡
sudo systemctl enable hotsearch-crawler

# 5. å¯åŠ¨æœåŠ¡
sudo systemctl start hotsearch-crawler
```

## ğŸ® æœåŠ¡ç®¡ç†

### ä½¿ç”¨ç®¡ç†è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# æŸ¥çœ‹çŠ¶æ€
./manage.sh status

# å¯åŠ¨æœåŠ¡
./manage.sh start

# åœæ­¢æœåŠ¡
./manage.sh stop

# é‡å¯æœåŠ¡
./manage.sh restart

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
./manage.sh logs

# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
./manage.sh logs-app

# æŸ¥çœ‹æ•°æ®
./manage.sh data

# æ¸…ç†æ—§æ•°æ®
./manage.sh clean

# æµ‹è¯•è¿è¡Œ
./manage.sh test

# å¸è½½æœåŠ¡
./manage.sh uninstall
```

### ä½¿ç”¨ systemctl å‘½ä»¤

```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
sudo systemctl status hotsearch-crawler

# å¯åŠ¨æœåŠ¡
sudo systemctl start hotsearch-crawler

# åœæ­¢æœåŠ¡
sudo systemctl stop hotsearch-crawler

# é‡å¯æœåŠ¡
sudo systemctl restart hotsearch-crawler

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
sudo journalctl -u hotsearch-crawler -f

# æŸ¥çœ‹æœ€è¿‘100è¡Œæ—¥å¿—
sudo journalctl -u hotsearch-crawler -n 100

# å¯ç”¨å¼€æœºè‡ªå¯
sudo systemctl enable hotsearch-crawler

# ç¦ç”¨å¼€æœºè‡ªå¯
sudo systemctl disable hotsearch-crawler
```

## ğŸ“Š ç›‘æ§å’Œç»´æŠ¤

### æ£€æŸ¥æœåŠ¡è¿è¡ŒçŠ¶æ€

```bash
# å¿«é€Ÿæ£€æŸ¥
sudo systemctl is-active hotsearch-crawler

# è¯¦ç»†çŠ¶æ€
./manage.sh status
```

### æŸ¥çœ‹æ—¥å¿—

```bash
# ç³»ç»Ÿæ—¥å¿—ï¼ˆæ¨èç”¨äºè°ƒè¯•ï¼‰
sudo journalctl -u hotsearch-crawler -f

# åº”ç”¨æ—¥å¿—
tail -f logs/crawler_*.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
sudo journalctl -u hotsearch-crawler -p err
```

### æ•°æ®ç®¡ç†

```bash
# æŸ¥çœ‹æ•°æ®æ‘˜è¦
python3 view_data.py

# æŸ¥çœ‹æŒ‡å®šå¹³å°
python3 view_data.py --platform å“”å“©å“”å“©

# æŸ¥çœ‹æ•°æ®æ–‡ä»¶å¤§å°
du -sh data/

# ç»Ÿè®¡æ–‡ä»¶æ•°é‡
ls -l data/*.json | wc -l

# æ¸…ç†æ—§æ•°æ®ï¼ˆä¿ç•™æœ€è¿‘7å¤©ï¼‰
./manage.sh clean
```

### è‡ªåŠ¨æ¸…ç†è„šæœ¬

åˆ›å»ºå®šæ—¶ä»»åŠ¡è‡ªåŠ¨æ¸…ç†æ—§æ•°æ®ï¼š

```bash
# ç¼–è¾‘crontab
crontab -e

# æ·»åŠ ä»¥ä¸‹è¡Œï¼ˆæ¯å¤©å‡Œæ™¨3ç‚¹æ¸…ç†ï¼‰
0 3 * * * find /path/to/çƒ­ç‚¹çˆ¬å–/data -name "hotsearch_*.json" -mtime +7 -delete
```

## ğŸ”’ å®‰å…¨å»ºè®®

### 1. ä½¿ç”¨érootç”¨æˆ·è¿è¡Œ

```bash
# æœåŠ¡é…ç½®ä¸­ä½¿ç”¨æ™®é€šç”¨æˆ·
User=your-username
```

### 2. é™åˆ¶æ–‡ä»¶æƒé™

```bash
# è®¾ç½®åˆé€‚çš„æƒé™
chmod 755 *.sh *.py
chmod 644 *.json *.txt *.md
chmod 700 data/ logs/
```

### 3. é˜²ç«å¢™é…ç½®

çˆ¬è™«åªéœ€è¦å‡ºç«™ç½‘ç»œè®¿é—®ï¼Œä¸éœ€è¦å¼€æ”¾ä»»ä½•ç«¯å£ã€‚

### 4. å®šæœŸå¤‡ä»½

```bash
# å¤‡ä»½æ•°æ®åˆ°å…¶ä»–ä½ç½®
rsync -av data/ /backup/hotsearch/$(date +%Y%m%d)/
```

## ğŸš¨ æ•…éšœæ’æŸ¥

### é—®é¢˜1: æœåŠ¡å¯åŠ¨å¤±è´¥

```bash
# æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
sudo systemctl status hotsearch-crawler -l

# æŸ¥çœ‹æ—¥å¿—
sudo journalctl -u hotsearch-crawler -n 50

# æ£€æŸ¥Pythonè·¯å¾„
which python3

# æµ‹è¯•æ‰‹åŠ¨è¿è¡Œ
cd /path/to/çƒ­ç‚¹çˆ¬å–
python3 scheduler.py --once
```

### é—®é¢˜2: ä¾èµ–å®‰è£…å¤±è´¥

```bash
# ä½¿ç”¨å›½å†…é•œåƒ
pip3 install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# å‡çº§pip
pip3 install --upgrade pip
```

### é—®é¢˜3: æƒé™é”™è¯¯

```bash
# ç¡®ä¿ç›®å½•æƒé™æ­£ç¡®
sudo chown -R your-username:your-username /path/to/çƒ­ç‚¹çˆ¬å–

# ç¡®ä¿å¯ä»¥å†™å…¥æ•°æ®å’Œæ—¥å¿—
chmod 755 data/ logs/
```

### é—®é¢˜4: ç½‘ç»œè¿æ¥é—®é¢˜

```bash
# æµ‹è¯•ç½‘ç»œè¿æ¥
curl -I https://api.pearktrue.cn/api/dailyhot/

# æµ‹è¯•DNSè§£æ
nslookup api.pearktrue.cn

# æ£€æŸ¥ä»£ç†è®¾ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
echo $http_proxy
echo $https_proxy
```

### é—®é¢˜5: æœåŠ¡æ„å¤–åœæ­¢

```bash
# æŸ¥çœ‹æœåŠ¡æ—¥å¿—æŸ¥æ‰¾åŸå› 
sudo journalctl -u hotsearch-crawler -n 200

# æ£€æŸ¥ç³»ç»Ÿèµ„æº
free -h
df -h

# é‡å¯æœåŠ¡
sudo systemctl restart hotsearch-crawler
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. è°ƒæ•´è¿è¡Œé—´éš”

ç¼–è¾‘ `config.json`ï¼š
```json
{
  "scheduler": {
    "interval_hours": 2
  }
}
```

é‡å¯æœåŠ¡ç”Ÿæ•ˆï¼š
```bash
sudo systemctl restart hotsearch-crawler
```

### 2. é™åˆ¶å†å²æ•°æ®

åªä¿å­˜æœ€æ–°æ•°æ®ï¼Œä¸ä¿å­˜å†å²ï¼š
```json
{
  "scheduler": {
    "save_history": false
  }
}
```

### 3. èµ„æºé™åˆ¶

åœ¨æœåŠ¡é…ç½®ä¸­æ·»åŠ èµ„æºé™åˆ¶ï¼š
```ini
[Service]
MemoryLimit=200M
CPUQuota=20%
```

## ğŸ”„ æ›´æ–°éƒ¨ç½²

```bash
# 1. åœæ­¢æœåŠ¡
sudo systemctl stop hotsearch-crawler

# 2. å¤‡ä»½æ•°æ®
cp -r data/ data.backup/

# 3. æ›´æ–°ä»£ç 
rsync -av new-code/ /path/to/çƒ­ç‚¹çˆ¬å–/

# 4. æ›´æ–°ä¾èµ–
pip3 install -r requirements.txt --upgrade

# 5. æµ‹è¯•è¿è¡Œ
python3 scheduler.py --once

# 6. é‡å¯æœåŠ¡
sudo systemctl start hotsearch-crawler
```

## ğŸ“± è¿œç¨‹è®¿é—®æ•°æ®

### é€šè¿‡SSHæŸ¥çœ‹

```bash
# SSHç™»å½•å
./manage.sh data
```

### é€šè¿‡SCPä¸‹è½½

```bash
# ä¸‹è½½æœ€æ–°æ•°æ®åˆ°æœ¬åœ°
scp user@server:/path/to/çƒ­ç‚¹çˆ¬å–/data/latest.json ./
```

### æ­å»ºç®€å•WebæœåŠ¡ï¼ˆå¯é€‰ï¼‰

```bash
# åœ¨dataç›®å½•å¯åŠ¨HTTPæœåŠ¡å™¨ï¼ˆä»…ç”¨äºä¸´æ—¶è®¿é—®ï¼‰
cd data
python3 -m http.server 8000

# ç„¶åé€šè¿‡æµè§ˆå™¨è®¿é—®
# http://your-server-ip:8000/latest.json
```

## âœ… éƒ¨ç½²æ£€æŸ¥æ¸…å•

éƒ¨ç½²å®Œæˆåï¼Œæ£€æŸ¥ä»¥ä¸‹é¡¹ç›®ï¼š

- [ ] Pythonç¯å¢ƒæ­£ç¡®å®‰è£…ï¼ˆpython3 --versionï¼‰
- [ ] ä¾èµ–åŒ…å®‰è£…æˆåŠŸï¼ˆpip3 listï¼‰
- [ ] æµ‹è¯•è¿è¡ŒæˆåŠŸï¼ˆpython3 scheduler.py --onceï¼‰
- [ ] systemdæœåŠ¡å·²åˆ›å»º
- [ ] æœåŠ¡è¿è¡Œæ­£å¸¸ï¼ˆsystemctl statusï¼‰
- [ ] å¼€æœºè‡ªå¯å·²å¯ç”¨ï¼ˆsystemctl is-enabledï¼‰
- [ ] æ•°æ®æ–‡ä»¶æ­£å¸¸ç”Ÿæˆï¼ˆls data/ï¼‰
- [ ] æ—¥å¿—æ–‡ä»¶æ­£å¸¸å†™å…¥ï¼ˆls logs/ï¼‰
- [ ] å¯ä»¥æŸ¥çœ‹æ•°æ®ï¼ˆpython3 view_data.pyï¼‰

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼š
1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
2. æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIæœåŠ¡çŠ¶æ€
3. ç¡®è®¤Pythonç‰ˆæœ¬å’Œä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®
4. å‚è€ƒæ•…éšœæ’æŸ¥ç« èŠ‚

---

**éƒ¨ç½²å®Œæˆåï¼Œçˆ¬è™«å°†æ¯å°æ—¶è‡ªåŠ¨è¿è¡Œï¼Œæ•°æ®ä¿å­˜åœ¨ `data/` ç›®å½•ï¼**
